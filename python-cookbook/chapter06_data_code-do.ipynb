{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章：数据编码和处理\n",
    "这一章主要讨论使用Python处理各种不同方式编码的数据，比如CSV文件，JSON，XML和二进制包装记录。\n",
    "\n",
    "和数据结构那一章不同的是，这章不会讨论特殊的算法问题，而是关注于怎样获取和存储这些格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读写CSV数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想读写一个CSV格式的文件。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "对于大多数的CSV格式的数据读写问题，都可以使用 csv 库。 例如：假设你在一个名叫 `stocks.csv` 文件中有一些股票市场数据，就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "True\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "True\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "True\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "True\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "True\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 读取csv数据，转为元组序列\n",
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(isinstance(row, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[0], row[1], row[2], row[3], row[4], row[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中，`row` 会是一个列表。\n",
    "\n",
    "因此，为了访问某个字段，你需要使用下标。\n",
    "\n",
    "如 `row[0]` 访问 `Symbol`的值，`row[4]` 访问 `Change` 的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "AA\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "AIG\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "AXP\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "BA\n",
      "Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "C\n",
      "Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n",
      "CAT\n"
     ]
    }
   ],
   "source": [
    "# 使用下标访问通常会引起混淆，使用 命名元组来索引数据。\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)  # 列名\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        # r is list\n",
    "        row = Row(*r)\n",
    "        print(row)\n",
    "        print(row.Symbol)  # 使用列名索引数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码允许使用列名如 `row.Symbol` 和 `row.Change` 代替下标访问数据。\n",
    "\n",
    "需要注意的是：这个只有在 **列名是合法的Python标识符** 的时候才生效。\n",
    "\n",
    "如果不是的话，你可能需要修改下原始的列名(如将非标识符字符替换成下划线之类的)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个选择就是**将数据读取到一个字典序列**中去。可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "AA\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "AIG\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "AXP\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(row['Symbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个版本中，你可以使用列名去访问每一行的数据了。比如，`row['Symbol']` 或者 `row['Change']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了写入CSV数据，你仍然可以使用csv模块，不过这时候先创建一个 `writer` 对象。例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你有一个字典序列的数据\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "        {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "        {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "你应该优先选择 `csv` 模块分割或解析CSV数据。例如，你可能会像编写类似下面这样的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']\n",
      "['\"AA\"', '39.48', '\"6/11/2007\"', '\"9:36am\"', '-0.18', '181800\\n']\n",
      "['\"AIG\"', '71.38', '\"6/11/2007\"', '\"9:36am\"', '-0.15', '195500\\n']\n",
      "['\"AXP\"', '62.58', '\"6/11/2007\"', '\"9:36am\"', '-0.46', '935000\\n']\n",
      "['\"B', 'A\"', '98.31', '\"6/11/2007\"', '\"9:36am\"', '+0.12', '104800\\n']\n",
      "['\"C\"', '53.08', '\"6/11/2007\"', '\"9:36am\"', '-0.25', '360900\\n']\n",
      "['\"CAT\"', '78.29', '\"6/11/2007\"', '\"9:36am\"', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。\n",
    "* 如果某些字段值被引号包围，你不得不去除这些引号。\n",
    "* 如果一个被引号包围的字段碰巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。\n",
    "\n",
    "默认情况下，csv 库可识别Microsoft Excel所使用的CSV编码规则。这也是最常见的形式，并且也会给你带来最好的兼容性。\n",
    "\n",
    "然而，如果你查看csv的文档，就会发现有很多种方法将它应用到其他编码格式上(如修改分割字符等)。 例如，如果你想读取以tab分割的数据，可以这样做：\n",
    "\n",
    "```python\n",
    "# Example of reading tab-separated values\n",
    "with open('stock.tsv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        # Process row\n",
    "        print(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你正在读取CSV数据并将它们转换为 命名元组，需要注意对列名进行合法性认证。\n",
    "\n",
    "例如，一个CSV格式文件有一个包含非法标识符的列头行，类似下面这样：\n",
    "```\n",
    "Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452\n",
    "```\n",
    "\n",
    "这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。\n",
    "\n",
    "为了解决这问题，你可能不得不先去修正列标题。例如，可以像下面这样在非法标识符上使用一个正则表达式替换：\n",
    "\n",
    "```python\n",
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有重要的一点需要强调的是，csv产生的数据都是**字符串类型**的，它不会做任何其他类型的转换。\n",
    "\n",
    "如果你需要做这样的类型转换，你必须自己手动去实现。下面是一个在CSV数据上执行其他类型转换的例子：\n",
    "```python\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，下面是一个转换字典中特定字段的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n",
      "OrderedDict([('Symbol', 'AA'), ('Price', 39.48), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.18), ('Volume', 181800)])\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', 71.38), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.15), ('Volume', 195500)])\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', 62.58), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.46), ('Volume', 935000)])\n"
     ]
    }
   ],
   "source": [
    "print('Reading as dicts with type conversion')\n",
    "\n",
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常来讲，你可能并不想过多去考虑这些转换问题。在实际情况中，CSV文件都或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。\n",
    "\n",
    "因此，除非你的数据确实有保障是准确无误的，否则你必须考虑这些问题(你可能需要增加合适的错误处理机制)。\n",
    "\n",
    "最后，如果你读取CSV数据的目的是做数据分析和统计的话，你可能需要看一看 `Pandas` 包。\n",
    "\n",
    "Pandas 包含了一个非常方便的函数叫 `pandas.read_csv()`，它可以加载CSV数据到一个 `DataFrame` 对象中去。 然后利用这个对象你就可以生成各种形式的统计、过滤数据以及执行其他高级操作了。在6.13小节中会有这样一个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 读写JSON数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "读写JSON(JavaScript Object Notation)编码格式的数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "`json` 模块提供了一种很简单的方式来编码和解码JSON数据。其中两个主要的函数是 `json.dumps()` 和 `json.loads()`，\n",
    "\n",
    "要比其他序列化函数库如pickle的接口少得多。 下面演示如何将一个Python数据结构转换为JSON："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name': 'ACME',\n",
    "    'shares': 100,\n",
    "    'price': 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面演示如何将一个JSON编码的字符串转换回一个Python数据结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ACME', 'shares': 100, 'price': 542.23}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(json_str)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你要处理的是文件而不是字符串，你可以使用 `json.dump()` 和 `json.load()` 来编码和解码JSON数据。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "JSON编码支持的基本数据类型为 `None`，`bool`，`int`，`float` 和 `str`，以及包含这些类型数据的 `lists`，`tuples` 和 `dictionaries`。\n",
    "\n",
    "对于`dictionaries`，`keys` 需要是字符串类型（字典中任何非字符串类型的key在编码时会先转换为字符串）。\n",
    "\n",
    "为了遵循JSON规范，你应该只编码Python的 `lists` 和 `dictionaries`。 而且，在web应用程序中，顶层对象被编码为一个字典是一个标准做法。\n",
    "\n",
    "JSON编码的格式对于Python语法而已几乎是完全一样的，除了一些小的差异之外。比如，True会被映射为true，False被映射为false，而None会被映射为null。\n",
    "\n",
    "下面是一个例子，演示了编码后的字符串效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(False)\n",
    "\n",
    "d = {\n",
    "    'a': True,\n",
    "    'b': 'Hello',\n",
    "    'c': None\n",
    "    }\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你试着去检查JSON解码后的数据，你通常很难通过简单的打印来确定它的结构，特别是当数据的嵌套结构层次很深或者包含大量的字段时。\n",
    "\n",
    "为了解决这个问题，可以考虑使用 `pprint` 模块的 `pprint()` 函数来代替普通的 `print()` 函数。\n",
    "\n",
    "它会按照key的字母顺序并以一种更加美观的方式输出。 下面是一个演示如何漂亮的打印输出Twitter上搜索结果的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c709c61d976b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "\n",
    "u = urlopen('https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来讲，JSON解码会根据提供的数据创建 `dicts` 或`lists`。\n",
    "\n",
    "如果你想要创建其他类型的对象，可以给 `json.loads()` 传递 `object_pairs_hook` 或 `object_hook` 参数。\n",
    "\n",
    "例如，下面是演示如何解码JSON数据并在一个 `OrderedDict` 中保留其顺序的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是如何将一个JSON字典转换为一个Python对象例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(s, object_hook=JSONObject)\n",
    "data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON解码后的字典作为一个单个参数传递给 `__init__()`。然后，你就可以随意使用它了，比如作为一个实例字典来直接使用它。\n",
    "\n",
    "在编码JSON的时候，还有一些选项很有用。 如果你想获得漂亮的格式化字符串后输出，可以使用 `json.dumps()` 的 `indent` 参数。 它会使得输出和pprint()函数效果类似。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}\n"
     ]
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对象实例通常并不是JSON可序列化的。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'Point' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-54699a8f2307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'Point' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "p = Point(2, 3)\n",
    "json.dumps(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你想反过来获取这个实例，可以这样做：\n",
    "# Dictionary mapping names to known classes\n",
    "classes = {\n",
    "    'Point' : Point\n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "        return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是如何使用这些函数的例子：\n",
    "p = Point(2, 3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x28df66410b8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json 模块还有很多其他选项来控制更低级别的数字、特殊值如NaN等的解析。 可以参考官方文档获取更多细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解析简单的XML数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想从一个简单的XML文档中提取数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "可以使用 `xml.etree.ElementTree` 模块从简单的XML文档中提取数据。为了演示，假设你想解析 Planet Python上的RSS源。下面是相应的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed an dparse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Python: Build and Submit HTML Forms With Django – Part 4\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-forms-4/\n",
      "Python for Beginners: Create Decorators Using Classes in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/create-decorators-using-classes-in-python\n",
      "Quansight Labs Blog: IPython 8.0, Lessons learned maintaining software\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://labs.quansight.org/blog/2022/01/ipython-8.0-lessons-learned-maintaining-software/\n",
      "Python Circle: Django vs Node.js: Which One Is Better for Web Development?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pythoncircle.com/post/757/django-vs-nodejs-which-one-is-better-for-web-development/\n",
      "Kay Hayen: Nuitka Release 0.6.19\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://nuitka.net/posts/nuitka-release-0619.html\n",
      "Test and Code: 175: Who Should Do QA?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testandcode.com/175\n",
      "Read the Docs: Read the Docs newsletter - January 2022\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://blog.readthedocs.com/newsletter-january-2022/\n",
      "TestDriven.io: Introduction to Django Channels\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testdriven.io/blog/django-channels/\n",
      "PyCoder’s Weekly: Issue #507 (Jan. 11, 2022)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pycoders.com/issues/507\n",
      "Python for Beginners: Check For Prime Number in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/check-for-prime-number-in-python\n",
      "Real Python: Working With Pipenv\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/courses/working-with-pipenv/\n",
      "Sumana Harihareswara - Cogito, Ergo Sumana: Some Novel Python Packaging/Distribution/Inspection/Installation Projects\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://harihareswara.net/posts/2021/some-novel-python-packagingdistributioninspectioninstallation-projects/\n",
      "Python GUIs: Using Layouts to Position Widgets in PySide6 — Use layouts to effortlessly position widgets within the window (updated for PySide6)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonguis.com/tutorials/pyside6-layouts/\n",
      "Codementor: One-Hot Encoding in Data Science\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.codementor.io/abdelfettahbesbes/one-hot-encoding-in-data-science-1pe0lftu21\n",
      "Inspired Python: Solving Wordle Puzzles with Basic Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.inspiredpython.com/article/solving-wordle-puzzles-with-basic-python\n",
      "Real Python: Build and Handle POST Requests in Django – Part 3\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-post-3/\n",
      "ItsMyCode: How to Fix: KeyError in Pandas?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-keyerror-in-pandas/\n",
      "David Amos: 5 Ways To Use Python On An iPad\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://davidamos.dev/5-ways-to-use-python-on-an-ipad/\n",
      "ItsMyCode: How to Fix in Python ValueError: Trailing data?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-in-python-valueerror-trailing-data/\n",
      "Mike Driscoll: PyDev of the Week:  Lais Carvalho\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.blog.pythonlibrary.org/2022/01/10/pydev-of-the-week-lais-carvalho/\n",
      "Zato Blog: API development workflow with Zato\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://zato.io/blog/posts/zato-dev-workflow.html\n",
      "Matt Layman: Most Abstract Function First Is Better\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.mattlayman.com/blog/2022/most-abstract-function-first-better/\n",
      "Armin Ronacher: Dependency Risk and Funding\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding\n",
      "ItsMyCode: [Solved] NameError: name &#8216;pd&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-pd-is-not-defined/\n",
      "ItsMyCode: [Solved] NameError: name &#8216;np&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-np-is-not-defined/\n"
     ]
    }
   ],
   "source": [
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(data)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "在很多应用程序中处理XML编码格式的数据是很常见的。不仅因为XML在Internet上面已经被广泛应用于数据交换，同时它也是一种存储应用程序数据的常用格式(比如字处理，音乐库等)。\n",
    "\n",
    "在很多情况下，当使用XML来仅仅存储数据的时候，对应的文档结构非常紧凑并且直观。 例如，上面例子中的RSS订阅源类似于下面的格式：\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "    <channel>\n",
    "        <title>Planet Python</title>\n",
    "        <link>http://planet.python.org/</link>\n",
    "        <language>en</language>\n",
    "        <description>Planet Python - http://planet.python.org/</description>\n",
    "        <item>\n",
    "            <title>Steve Holden: Python for Data Analysis</title>\n",
    "            <guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n",
    "            <link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n",
    "            <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "            <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Python Diary: Been playing around with Object Databases</title>\n",
    "            <guid>http://www.pythondiary.com/...-object-databases.html</guid>\n",
    "            <link>http://www.pythondiary.com/...-object-databases.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "        </item>\n",
    "        ...\n",
    "    </channel>\n",
    "</rss>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xml.etree.ElementTree.parse()` 函数解析整个XML文档并将其转换成一个文档对象。\n",
    "\n",
    "然后，你就能使用 `find()`、`iterfind()` 和 `findtext()` 等方法来搜索特定的XML元素了。\n",
    "\n",
    "这些函数的参数就是某个指定的标签名，例如 `channel/item` 或 `title`。\n",
    "\n",
    "每次指定某个标签时，你需要遍历整个文档结构。每次搜索操作会从一个起始元素开始进行。同样，每次操作所指定的标签名也是起始元素的相对路径。\n",
    "\n",
    "例如，执行 `doc.iterfind('channel/item')` 来搜索所有在 `channel` 元素下面的 `item` 元素。\n",
    "\n",
    "`doc` 代表文档的最顶层(也就是第一级的 rss 元素)。 然后接下来的调用 `item.findtext()` 会从已找到的 `item` 元素位置开始搜索。\n",
    "\n",
    "`ElementTree` 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有用。\n",
    "\n",
    "`tag` 属性包含了标签的名字，`text` 属性包含了内部的文本，而 `get()` 方法能获取属性值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x28df65c19e8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x0000028DF66490E8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一点要强调的是 `xml.etree.ElementTree` 并不是XML解析的唯一方法。\n",
    "\n",
    "对于更高级的应用程序，你需要考虑使用 `lxml`。 它使用了和ElementTree同样的编程接口，因此上面的例子同样也适用于lxml。\n",
    "\n",
    "你只需要将刚开始的import语句换成 `from lxml.etree import parse` 就行了。\n",
    "\n",
    "`lxml` 完全遵循XML标准，并且速度也非常快，同时还支持验证，XSLT，和XPath等特性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 增量式解析大型XML文件\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想使用尽可能少的内存从一个超大的XML文档中提取数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "任何时候只要你遇到**增量式的数据处理**时，第一时间就应该想到**迭代器和生成器**。\n",
    "\n",
    "下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型XML文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # skip the root element\n",
    "    next(doc)\n",
    "\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了测试这个函数，你需要先有一个大型的XML文件。 通常你可以在政府网站或公共数据网站上找到这样的文件。 例如，你可以下载XML格式的芝加哥城市道路坑洼数据库。 在写这本书的时候，下载文件已经包含超过100,000行数据，编码格式类似于下面这样：\n",
    "```python\n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个脚本唯一的问题是它会先将整个XML文件加载到内存中然后解析。 在我的机器上，为了运行这个程序需要用到450MB左右的内存空间。 如果使用如下代码，程序只需要修改一点点：\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```\n",
    "结果是：这个版本的代码运行时只需要7MB的内存–大大节约了内存资源。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "这一节的技术会依赖 `ElementTree` 模块中的两个核心功能。\n",
    "* 第一，`iterparse()` 方法允许对XML文档进行增量操作。使用时，你需要提供文件名和一个包含下面一种或多种类型的事件列表：`start` , `end`, `start-ns` 和 `end-ns` 。\n",
    "* 由 `iterparse()` 创建的迭代器会产生形如 `(event, elem)` 的元组， 其中 `event` 是上述事件列表中的某一个，而 `elem` 是相应的XML元素。例如：\n",
    "```python\n",
    ">>> data = iterparse('potholes.xml',('start','end'))\n",
    ">>> next(data)\n",
    "('start', <Element 'response' at 0x100771d60>)\n",
    ">>> next(data)\n",
    "('start', <Element 'row' at 0x100771e68>)\n",
    ">>> next(data)\n",
    "('start', <Element 'row' at 0x100771fc8>)\n",
    ">>> next(data)\n",
    "('start', <Element 'creation_date' at 0x100771f18>)\n",
    ">>> next(data)\n",
    "('end', <Element 'creation_date' at 0x100771f18>)\n",
    ">>> next(data)\n",
    "('start', <Element 'status' at 0x1006a7f18>)\n",
    ">>> next(data)\n",
    "('end', <Element 'status' at 0x1006a7f18>)\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`start` 事件在某个元素第一次被创建并且还没有被插入其他数据(如子元素)时被创建。 而 `end` 事件在某个元素已经完成时被创建。\n",
    "\n",
    "尽管没有在例子中演示，`start-ns` 和 `end-ns` 事件被用来处理XML文档命名空间的声明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这本节例子中，`start` 和 `end` 事件被用来管理元素和标签栈。\n",
    "\n",
    "**栈**代表了文档被解析时的层次结构，还被用来判断某个元素是否匹配传给函数 `parse_and_remove()` 的路径。如果匹配，就利用 `yield` 语句向调用者返回这个元素。\n",
    "\n",
    "在 `yield` 之后的下面这个语句才是使得程序占用极少内存的 `ElementTree` 的核心特性：\n",
    "```python\n",
    "elem_stack[-2].remove(elem)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个语句使得之前由 `yield` 产生的元素从它的父节点中删除掉。假设已经没有其它的地方引用这个元素了，那么这个元素就被销毁并回收内存。\n",
    "\n",
    "对节点的迭代式解析和删除的最终效果就是一个在文档上高效的增量式清扫过程。文档树结构从始自终没被完整的创建过。尽管如此，还是能通过上述简单的方式来处理这个XML数据。\n",
    "\n",
    "这种方案的主要缺陷就是它的**运行性能**。 我自己测试的结果是，读取整个文档到内存中的版本的运行速度差不多是增量式处理版本的两倍快。但是它却使用了超过后者60倍的内存。\n",
    "\n",
    "**因此，如果你更关心内存使用量的话，那么就可以使用这种增量式处理方式。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 将字典转换为XML\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想使用一个Python字典存储数据，并将它转换成XML格式。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "尽管 `xml.etree.ElementTree` 库通常用来做解析工作，其实它也可以创建XML文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    \"\"\"Turn a simple dict of key/value pairs into XML\"\"\"\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x0000016C37A11C78>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = { 'name': 'GOOG', 'shares': 100, 'price':490.1}\n",
    "e = dict_to_xml('stock', s)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换结果是一个 `Element` 实例。\n",
    "\n",
    "对于`I/O`操作，使用 `xml.etree.ElementTree` 中的 `tostring()` 函数很容易就能将它转换成一个字节字符串。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import tostring\n",
    "\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想给某个元素添加属性值，可以使用 `set()` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock _id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.set('_id', '1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你还想保持元素的顺序，可以考虑构造一个 `OrderedDict` 来代替一个普通的字典。请参考1.7小节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "当创建XML的时候，你被限制只能构造字符串类型的值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml_str(tag, d):\n",
    "    \"\"\"Turn a simple dict of key/value pairs into XML\"\"\"\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key, val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当字典的值中包含一些特殊字符的时候会怎么处理呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'name': '<spam>'}\n",
    "\n",
    "# String creation\n",
    "dict_to_xml_str('item', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proper XML creation\n",
    "e = dict_to_xml('item', d)\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到程序的后面那个例子中，字符 `'<' 和 '>'` 被替换成了 `&lt;` 和 `&gt;`\n",
    "\n",
    "下面仅供参考，如果你需要手动去转换这些字符， 可以使用 `xml.sax.saxutils` 中的 `escape()` 和 `unescape()` 函数。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了能创建正确的输出外，还有另外一个原因推荐你创建 `Element` 实例而不是字符串，那就是使用字符串组合构造一个更大的文档并不是那么容易。\n",
    "\n",
    "而 `Element` 实例可以不用考虑解析XML文本的情况下通过多种方式被处理。也就是说，你可以在一个高级数据结构上完成你所有的操作，并在最后以字符串的形式将其输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 解析和修改XML\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想读取一个XML文档，对它最一些修改，然后将结果写回XML文档。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "使用 `xml.etree.ElementTree` 模块可以很容易的处理这些任务。\n",
    "\n",
    "第一步是以通常的方式来解析这个文档。例如，假设你有一个名为 `pred.xml` 的文档，类似下面这样："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个利用 ElementTree 来读取这个文档并对它做一些修改的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stop' at 0x0000016C37A48B88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "\n",
    "doc = parse('./pred.xml')\n",
    "root = doc.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a few elements\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert a new element after <nm>...</nm>\n",
    "root.getchildren().index(root.find('nm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back to a file\n",
    "doc.write('newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "修改一个XML文档结构是很容易的，但是你必须牢记的是**所有的修改都是针对父节点元素**，将它作为一个**列表**来处理。\n",
    "\n",
    "* 如果你删除某个元素，通过调用父节点的 `remove()` 方法从它的直接父节点中删除。\n",
    "* 如果你插入或增加新的元素，你同样使用父节点元素的 `insert()` 和 `append()` 方法。还能对元素使用索引和切片操作，比如 `element[i]` 或 `element[i:j]`\n",
    "* 如果你需要创建新的元素，可以使用本节方案中演示的 `Element` 类。我们在6.5小节已经详细讨论过了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "145699e85a40168331a7cb4ae89765d59b9032ff9abe784a3aea13b1452c5e16"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('pytorch1.8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
