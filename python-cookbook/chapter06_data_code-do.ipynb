{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章：数据编码和处理\n",
    "这一章主要讨论使用Python处理各种不同方式编码的数据，比如CSV文件，JSON，XML和二进制包装记录。\n",
    "\n",
    "和数据结构那一章不同的是，这章不会讨论特殊的算法问题，而是关注于怎样获取和存储这些格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读写CSV数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想读写一个CSV格式的文件。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "对于大多数的CSV格式的数据读写问题，都可以使用 csv 库。 例如：假设你在一个名叫 `stocks.csv` 文件中有一些股票市场数据，就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "True\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "True\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "True\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "True\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "True\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 读取csv数据，转为元组序列\n",
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(isinstance(row, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[0], row[1], row[2], row[3], row[4], row[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中，`row` 会是一个列表。\n",
    "\n",
    "因此，为了访问某个字段，你需要使用下标。\n",
    "\n",
    "如 `row[0]` 访问 `Symbol`的值，`row[4]` 访问 `Change` 的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "AA\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "AIG\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "AXP\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "BA\n",
      "Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "C\n",
      "Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n",
      "CAT\n"
     ]
    }
   ],
   "source": [
    "# 使用下标访问通常会引起混淆，使用 命名元组来索引数据。\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)  # 列名\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        # r is list\n",
    "        row = Row(*r)\n",
    "        print(row)\n",
    "        print(row.Symbol)  # 使用列名索引数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码允许使用列名如 `row.Symbol` 和 `row.Change` 代替下标访问数据。\n",
    "\n",
    "需要注意的是：这个只有在 **列名是合法的Python标识符** 的时候才生效。\n",
    "\n",
    "如果不是的话，你可能需要修改下原始的列名(如将非标识符字符替换成下划线之类的)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个选择就是**将数据读取到一个字典序列**中去。可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "AA\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "AIG\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "AXP\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(row['Symbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个版本中，你可以使用列名去访问每一行的数据了。比如，`row['Symbol']` 或者 `row['Change']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了写入CSV数据，你仍然可以使用csv模块，不过这时候先创建一个 `writer` 对象。例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你有一个字典序列的数据\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "        {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "        {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "你应该优先选择 `csv` 模块分割或解析CSV数据。例如，你可能会像编写类似下面这样的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']\n",
      "['\"AA\"', '39.48', '\"6/11/2007\"', '\"9:36am\"', '-0.18', '181800\\n']\n",
      "['\"AIG\"', '71.38', '\"6/11/2007\"', '\"9:36am\"', '-0.15', '195500\\n']\n",
      "['\"AXP\"', '62.58', '\"6/11/2007\"', '\"9:36am\"', '-0.46', '935000\\n']\n",
      "['\"B', 'A\"', '98.31', '\"6/11/2007\"', '\"9:36am\"', '+0.12', '104800\\n']\n",
      "['\"C\"', '53.08', '\"6/11/2007\"', '\"9:36am\"', '-0.25', '360900\\n']\n",
      "['\"CAT\"', '78.29', '\"6/11/2007\"', '\"9:36am\"', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。\n",
    "* 如果某些字段值被引号包围，你不得不去除这些引号。\n",
    "* 如果一个被引号包围的字段碰巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。\n",
    "\n",
    "默认情况下，csv 库可识别Microsoft Excel所使用的CSV编码规则。这也是最常见的形式，并且也会给你带来最好的兼容性。\n",
    "\n",
    "然而，如果你查看csv的文档，就会发现有很多种方法将它应用到其他编码格式上(如修改分割字符等)。 例如，如果你想读取以tab分割的数据，可以这样做：\n",
    "\n",
    "```python\n",
    "# Example of reading tab-separated values\n",
    "with open('stock.tsv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        # Process row\n",
    "        print(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你正在读取CSV数据并将它们转换为 命名元组，需要注意对列名进行合法性认证。\n",
    "\n",
    "例如，一个CSV格式文件有一个包含非法标识符的列头行，类似下面这样：\n",
    "```\n",
    "Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452\n",
    "```\n",
    "\n",
    "这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。\n",
    "\n",
    "为了解决这问题，你可能不得不先去修正列标题。例如，可以像下面这样在非法标识符上使用一个正则表达式替换：\n",
    "\n",
    "```python\n",
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有重要的一点需要强调的是，csv产生的数据都是**字符串类型**的，它不会做任何其他类型的转换。\n",
    "\n",
    "如果你需要做这样的类型转换，你必须自己手动去实现。下面是一个在CSV数据上执行其他类型转换的例子：\n",
    "```python\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，下面是一个转换字典中特定字段的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n",
      "OrderedDict([('Symbol', 'AA'), ('Price', 39.48), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.18), ('Volume', 181800)])\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', 71.38), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.15), ('Volume', 195500)])\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', 62.58), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.46), ('Volume', 935000)])\n"
     ]
    }
   ],
   "source": [
    "print('Reading as dicts with type conversion')\n",
    "\n",
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常来讲，你可能并不想过多去考虑这些转换问题。在实际情况中，CSV文件都或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。\n",
    "\n",
    "因此，除非你的数据确实有保障是准确无误的，否则你必须考虑这些问题(你可能需要增加合适的错误处理机制)。\n",
    "\n",
    "最后，如果你读取CSV数据的目的是做数据分析和统计的话，你可能需要看一看 `Pandas` 包。\n",
    "\n",
    "Pandas 包含了一个非常方便的函数叫 `pandas.read_csv()`，它可以加载CSV数据到一个 `DataFrame` 对象中去。 然后利用这个对象你就可以生成各种形式的统计、过滤数据以及执行其他高级操作了。在6.13小节中会有这样一个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 读写JSON数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "读写JSON(JavaScript Object Notation)编码格式的数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "`json` 模块提供了一种很简单的方式来编码和解码JSON数据。其中两个主要的函数是 `json.dumps()` 和 `json.loads()`，\n",
    "\n",
    "要比其他序列化函数库如pickle的接口少得多。 下面演示如何将一个Python数据结构转换为JSON："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name': 'ACME',\n",
    "    'shares': 100,\n",
    "    'price': 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面演示如何将一个JSON编码的字符串转换回一个Python数据结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ACME', 'shares': 100, 'price': 542.23}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(json_str)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你要处理的是文件而不是字符串，你可以使用 `json.dump()` 和 `json.load()` 来编码和解码JSON数据。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "JSON编码支持的基本数据类型为 `None`，`bool`，`int`，`float` 和 `str`，以及包含这些类型数据的 `lists`，`tuples` 和 `dictionaries`。\n",
    "\n",
    "对于`dictionaries`，`keys` 需要是字符串类型（字典中任何非字符串类型的key在编码时会先转换为字符串）。\n",
    "\n",
    "为了遵循JSON规范，你应该只编码Python的 `lists` 和 `dictionaries`。 而且，在web应用程序中，顶层对象被编码为一个字典是一个标准做法。\n",
    "\n",
    "JSON编码的格式对于Python语法而已几乎是完全一样的，除了一些小的差异之外。比如，True会被映射为true，False被映射为false，而None会被映射为null。\n",
    "\n",
    "下面是一个例子，演示了编码后的字符串效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(False)\n",
    "\n",
    "d = {\n",
    "    'a': True,\n",
    "    'b': 'Hello',\n",
    "    'c': None\n",
    "    }\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你试着去检查JSON解码后的数据，你通常很难通过简单的打印来确定它的结构，特别是当数据的嵌套结构层次很深或者包含大量的字段时。\n",
    "\n",
    "为了解决这个问题，可以考虑使用 `pprint` 模块的 `pprint()` 函数来代替普通的 `print()` 函数。\n",
    "\n",
    "它会按照key的字母顺序并以一种更加美观的方式输出。 下面是一个演示如何漂亮的打印输出Twitter上搜索结果的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c709c61d976b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "\n",
    "u = urlopen('https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来讲，JSON解码会根据提供的数据创建 `dicts` 或`lists`。\n",
    "\n",
    "如果你想要创建其他类型的对象，可以给 `json.loads()` 传递 `object_pairs_hook` 或 `object_hook` 参数。\n",
    "\n",
    "例如，下面是演示如何解码JSON数据并在一个 `OrderedDict` 中保留其顺序的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是如何将一个JSON字典转换为一个Python对象例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(s, object_hook=JSONObject)\n",
    "data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON解码后的字典作为一个单个参数传递给 `__init__()`。然后，你就可以随意使用它了，比如作为一个实例字典来直接使用它。\n",
    "\n",
    "在编码JSON的时候，还有一些选项很有用。 如果你想获得漂亮的格式化字符串后输出，可以使用 `json.dumps()` 的 `indent` 参数。 它会使得输出和pprint()函数效果类似。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}\n"
     ]
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对象实例通常并不是JSON可序列化的。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'Point' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-54699a8f2307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'Point' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "p = Point(2, 3)\n",
    "json.dumps(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你想反过来获取这个实例，可以这样做：\n",
    "# Dictionary mapping names to known classes\n",
    "classes = {\n",
    "    'Point' : Point\n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "        return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是如何使用这些函数的例子：\n",
    "p = Point(2, 3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x28df66410b8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json 模块还有很多其他选项来控制更低级别的数字、特殊值如NaN等的解析。 可以参考官方文档获取更多细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解析简单的XML数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想从一个简单的XML文档中提取数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "可以使用 `xml.etree.ElementTree` 模块从简单的XML文档中提取数据。为了演示，假设你想解析 Planet Python上的RSS源。下面是相应的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed an dparse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Python: Build and Submit HTML Forms With Django – Part 4\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-forms-4/\n",
      "Python for Beginners: Create Decorators Using Classes in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/create-decorators-using-classes-in-python\n",
      "Quansight Labs Blog: IPython 8.0, Lessons learned maintaining software\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://labs.quansight.org/blog/2022/01/ipython-8.0-lessons-learned-maintaining-software/\n",
      "Python Circle: Django vs Node.js: Which One Is Better for Web Development?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pythoncircle.com/post/757/django-vs-nodejs-which-one-is-better-for-web-development/\n",
      "Kay Hayen: Nuitka Release 0.6.19\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://nuitka.net/posts/nuitka-release-0619.html\n",
      "Test and Code: 175: Who Should Do QA?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testandcode.com/175\n",
      "Read the Docs: Read the Docs newsletter - January 2022\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://blog.readthedocs.com/newsletter-january-2022/\n",
      "TestDriven.io: Introduction to Django Channels\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testdriven.io/blog/django-channels/\n",
      "PyCoder’s Weekly: Issue #507 (Jan. 11, 2022)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pycoders.com/issues/507\n",
      "Python for Beginners: Check For Prime Number in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/check-for-prime-number-in-python\n",
      "Real Python: Working With Pipenv\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/courses/working-with-pipenv/\n",
      "Sumana Harihareswara - Cogito, Ergo Sumana: Some Novel Python Packaging/Distribution/Inspection/Installation Projects\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://harihareswara.net/posts/2021/some-novel-python-packagingdistributioninspectioninstallation-projects/\n",
      "Python GUIs: Using Layouts to Position Widgets in PySide6 — Use layouts to effortlessly position widgets within the window (updated for PySide6)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonguis.com/tutorials/pyside6-layouts/\n",
      "Codementor: One-Hot Encoding in Data Science\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.codementor.io/abdelfettahbesbes/one-hot-encoding-in-data-science-1pe0lftu21\n",
      "Inspired Python: Solving Wordle Puzzles with Basic Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.inspiredpython.com/article/solving-wordle-puzzles-with-basic-python\n",
      "Real Python: Build and Handle POST Requests in Django – Part 3\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-post-3/\n",
      "ItsMyCode: How to Fix: KeyError in Pandas?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-keyerror-in-pandas/\n",
      "David Amos: 5 Ways To Use Python On An iPad\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://davidamos.dev/5-ways-to-use-python-on-an-ipad/\n",
      "ItsMyCode: How to Fix in Python ValueError: Trailing data?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-in-python-valueerror-trailing-data/\n",
      "Mike Driscoll: PyDev of the Week:  Lais Carvalho\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.blog.pythonlibrary.org/2022/01/10/pydev-of-the-week-lais-carvalho/\n",
      "Zato Blog: API development workflow with Zato\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://zato.io/blog/posts/zato-dev-workflow.html\n",
      "Matt Layman: Most Abstract Function First Is Better\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.mattlayman.com/blog/2022/most-abstract-function-first-better/\n",
      "Armin Ronacher: Dependency Risk and Funding\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding\n",
      "ItsMyCode: [Solved] NameError: name &#8216;pd&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-pd-is-not-defined/\n",
      "ItsMyCode: [Solved] NameError: name &#8216;np&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-np-is-not-defined/\n"
     ]
    }
   ],
   "source": [
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(data)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "在很多应用程序中处理XML编码格式的数据是很常见的。不仅因为XML在Internet上面已经被广泛应用于数据交换，同时它也是一种存储应用程序数据的常用格式(比如字处理，音乐库等)。\n",
    "\n",
    "在很多情况下，当使用XML来仅仅存储数据的时候，对应的文档结构非常紧凑并且直观。 例如，上面例子中的RSS订阅源类似于下面的格式：\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "    <channel>\n",
    "        <title>Planet Python</title>\n",
    "        <link>http://planet.python.org/</link>\n",
    "        <language>en</language>\n",
    "        <description>Planet Python - http://planet.python.org/</description>\n",
    "        <item>\n",
    "            <title>Steve Holden: Python for Data Analysis</title>\n",
    "            <guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n",
    "            <link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n",
    "            <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "            <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Python Diary: Been playing around with Object Databases</title>\n",
    "            <guid>http://www.pythondiary.com/...-object-databases.html</guid>\n",
    "            <link>http://www.pythondiary.com/...-object-databases.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "        </item>\n",
    "        ...\n",
    "    </channel>\n",
    "</rss>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xml.etree.ElementTree.parse()` 函数解析整个XML文档并将其转换成一个文档对象。\n",
    "\n",
    "然后，你就能使用 `find()`、`iterfind()` 和 `findtext()` 等方法来搜索特定的XML元素了。\n",
    "\n",
    "这些函数的参数就是某个指定的标签名，例如 `channel/item` 或 `title`。\n",
    "\n",
    "每次指定某个标签时，你需要遍历整个文档结构。每次搜索操作会从一个起始元素开始进行。同样，每次操作所指定的标签名也是起始元素的相对路径。\n",
    "\n",
    "例如，执行 `doc.iterfind('channel/item')` 来搜索所有在 `channel` 元素下面的 `item` 元素。\n",
    "\n",
    "`doc` 代表文档的最顶层(也就是第一级的 rss 元素)。 然后接下来的调用 `item.findtext()` 会从已找到的 `item` 元素位置开始搜索。\n",
    "\n",
    "`ElementTree` 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有用。\n",
    "\n",
    "`tag` 属性包含了标签的名字，`text` 属性包含了内部的文本，而 `get()` 方法能获取属性值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x28df65c19e8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x0000028DF66490E8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一点要强调的是 `xml.etree.ElementTree` 并不是XML解析的唯一方法。\n",
    "\n",
    "对于更高级的应用程序，你需要考虑使用 `lxml`。 它使用了和ElementTree同样的编程接口，因此上面的例子同样也适用于lxml。\n",
    "\n",
    "你只需要将刚开始的import语句换成 `from lxml.etree import parse` 就行了。\n",
    "\n",
    "`lxml` 完全遵循XML标准，并且速度也非常快，同时还支持验证，XSLT，和XPath等特性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 增量式解析大型XML文件\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想使用尽可能少的内存从一个超大的XML文档中提取数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "任何时候只要你遇到**增量式的数据处理**时，第一时间就应该想到**迭代器和生成器**。\n",
    "\n",
    "下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型XML文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # skip the root element\n",
    "    next(doc)\n",
    "\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了测试这个函数，你需要先有一个大型的XML文件。 通常你可以在政府网站或公共数据网站上找到这样的文件。 例如，你可以下载XML格式的芝加哥城市道路坑洼数据库。 在写这本书的时候，下载文件已经包含超过100,000行数据，编码格式类似于下面这样：\n",
    "```python\n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个脚本唯一的问题是它会先将整个XML文件加载到内存中然后解析。 在我的机器上，为了运行这个程序需要用到450MB左右的内存空间。 如果使用如下代码，程序只需要修改一点点：\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n",
    "```\n",
    "结果是：这个版本的代码运行时只需要7MB的内存–大大节约了内存资源。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "这一节的技术会依赖 `ElementTree` 模块中的两个核心功能。\n",
    "* 第一，`iterparse()` 方法允许对XML文档进行增量操作。使用时，你需要提供文件名和一个包含下面一种或多种类型的事件列表：`start` , `end`, `start-ns` 和 `end-ns` 。\n",
    "* 由 `iterparse()` 创建的迭代器会产生形如 `(event, elem)` 的元组， 其中 `event` 是上述事件列表中的某一个，而 `elem` 是相应的XML元素。例如：\n",
    "```python\n",
    ">>> data = iterparse('potholes.xml',('start','end'))\n",
    ">>> next(data)\n",
    "('start', <Element 'response' at 0x100771d60>)\n",
    ">>> next(data)\n",
    "('start', <Element 'row' at 0x100771e68>)\n",
    ">>> next(data)\n",
    "('start', <Element 'row' at 0x100771fc8>)\n",
    ">>> next(data)\n",
    "('start', <Element 'creation_date' at 0x100771f18>)\n",
    ">>> next(data)\n",
    "('end', <Element 'creation_date' at 0x100771f18>)\n",
    ">>> next(data)\n",
    "('start', <Element 'status' at 0x1006a7f18>)\n",
    ">>> next(data)\n",
    "('end', <Element 'status' at 0x1006a7f18>)\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`start` 事件在某个元素第一次被创建并且还没有被插入其他数据(如子元素)时被创建。 而 `end` 事件在某个元素已经完成时被创建。\n",
    "\n",
    "尽管没有在例子中演示，`start-ns` 和 `end-ns` 事件被用来处理XML文档命名空间的声明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这本节例子中，`start` 和 `end` 事件被用来管理元素和标签栈。\n",
    "\n",
    "**栈**代表了文档被解析时的层次结构，还被用来判断某个元素是否匹配传给函数 `parse_and_remove()` 的路径。如果匹配，就利用 `yield` 语句向调用者返回这个元素。\n",
    "\n",
    "在 `yield` 之后的下面这个语句才是使得程序占用极少内存的 `ElementTree` 的核心特性：\n",
    "```python\n",
    "elem_stack[-2].remove(elem)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个语句使得之前由 `yield` 产生的元素从它的父节点中删除掉。假设已经没有其它的地方引用这个元素了，那么这个元素就被销毁并回收内存。\n",
    "\n",
    "对节点的迭代式解析和删除的最终效果就是一个在文档上高效的增量式清扫过程。文档树结构从始自终没被完整的创建过。尽管如此，还是能通过上述简单的方式来处理这个XML数据。\n",
    "\n",
    "这种方案的主要缺陷就是它的**运行性能**。 我自己测试的结果是，读取整个文档到内存中的版本的运行速度差不多是增量式处理版本的两倍快。但是它却使用了超过后者60倍的内存。\n",
    "\n",
    "**因此，如果你更关心内存使用量的话，那么就可以使用这种增量式处理方式。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 将字典转换为XML\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想使用一个Python字典存储数据，并将它转换成XML格式。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "尽管 `xml.etree.ElementTree` 库通常用来做解析工作，其实它也可以创建XML文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    \"\"\"Turn a simple dict of key/value pairs into XML\"\"\"\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x0000016C37A11C78>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = { 'name': 'GOOG', 'shares': 100, 'price':490.1}\n",
    "e = dict_to_xml('stock', s)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换结果是一个 `Element` 实例。\n",
    "\n",
    "对于`I/O`操作，使用 `xml.etree.ElementTree` 中的 `tostring()` 函数很容易就能将它转换成一个字节字符串。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import tostring\n",
    "\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想给某个元素添加属性值，可以使用 `set()` 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock _id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.set('_id', '1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你还想保持元素的顺序，可以考虑构造一个 `OrderedDict` 来代替一个普通的字典。请参考1.7小节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "当创建XML的时候，你被限制只能构造字符串类型的值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml_str(tag, d):\n",
    "    \"\"\"Turn a simple dict of key/value pairs into XML\"\"\"\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key, val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当字典的值中包含一些特殊字符的时候会怎么处理呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'name': '<spam>'}\n",
    "\n",
    "# String creation\n",
    "dict_to_xml_str('item', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proper XML creation\n",
    "e = dict_to_xml('item', d)\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到程序的后面那个例子中，字符 `'<' 和 '>'` 被替换成了 `&lt;` 和 `&gt;`\n",
    "\n",
    "下面仅供参考，如果你需要手动去转换这些字符， 可以使用 `xml.sax.saxutils` 中的 `escape()` 和 `unescape()` 函数。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了能创建正确的输出外，还有另外一个原因推荐你创建 `Element` 实例而不是字符串，那就是使用字符串组合构造一个更大的文档并不是那么容易。\n",
    "\n",
    "而 `Element` 实例可以不用考虑解析XML文本的情况下通过多种方式被处理。也就是说，你可以在一个高级数据结构上完成你所有的操作，并在最后以字符串的形式将其输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 解析和修改XML\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想读取一个XML文档，对它最一些修改，然后将结果写回XML文档。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "使用 `xml.etree.ElementTree` 模块可以很容易的处理这些任务。\n",
    "\n",
    "第一步是以通常的方式来解析这个文档。例如，假设你有一个名为 `pred.xml` 的文档，类似下面这样："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个利用 ElementTree 来读取这个文档并对它做一些修改的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stop' at 0x0000016C37A48B88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "\n",
    "doc = parse('./pred.xml')\n",
    "root = doc.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a few elements\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert a new element after <nm>...</nm>\n",
    "root.getchildren().index(root.find('nm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back to a file\n",
    "doc.write('newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "修改一个XML文档结构是很容易的，但是你必须牢记的是**所有的修改都是针对父节点元素**，将它作为一个**列表**来处理。\n",
    "\n",
    "* 如果你删除某个元素，通过调用父节点的 `remove()` 方法从它的直接父节点中删除。\n",
    "* 如果你插入或增加新的元素，你同样使用父节点元素的 `insert()` 和 `append()` 方法。还能对元素使用索引和切片操作，比如 `element[i]` 或 `element[i:j]`\n",
    "* 如果你需要创建新的元素，可以使用本节方案中演示的 `Element` 类。我们在6.5小节已经详细讨论过了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 利用命名空间解析XML文档\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想解析某个XML文档，文档中使用了XML命名空间。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "考虑下面这个使用了命名空间的文档：\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<top>\n",
    "    <author>David Beazley</author>\n",
    "    <content>\n",
    "        <html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
    "            <head>\n",
    "                <title>Hello World</title>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1>Hello World!</h1>\n",
    "            </body>\n",
    "        </html>\n",
    "    </content>\n",
    "</top>\n",
    "```\n",
    "\n",
    "如果你解析这个文档并执行普通的查询，你会发现这个并不是那么容易，因为所有步骤都变得相当的繁琐。\n",
    "\n",
    "```python\n",
    ">>> # Some queries that work\n",
    ">>> doc.findtext('author')\n",
    "'David Beazley'\n",
    ">>> doc.find('content')\n",
    "<Element 'content' at 0x100776ec0>\n",
    ">>> # A query involving a namespace (doesn't work)\n",
    ">>> doc.find('content/html')\n",
    ">>> # Works if fully qualified\n",
    ">>> doc.find('content/{http://www.w3.org/1999/xhtml}html')\n",
    "<Element '{http://www.w3.org/1999/xhtml}html' at 0x1007767e0>\n",
    ">>> # Doesn't work\n",
    ">>> doc.findtext('content/{http://www.w3.org/1999/xhtml}html/head/title')\n",
    ">>> # Fully qualified\n",
    ">>> doc.findtext('content/{http://www.w3.org/1999/xhtml}html/'\n",
    "... '{http://www.w3.org/1999/xhtml}head/{http://www.w3.org/1999/xhtml}title')\n",
    "'Hello World'\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以通过将命名空间处理逻辑包装为一个工具类来简化这个过程\n",
    "class XMLNamespaces:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.namespaces = {}\n",
    "        for name, uri in kwargs.items():\n",
    "            self.register(name, uri)\n",
    "    \n",
    "    def register(self, name, uri):\n",
    "        self.namespaces[name] = '{'+uri+'}'\n",
    "    \n",
    "    def __call__(self, path):\n",
    "        return path.format_map(self.namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3a06cd68d1e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXMLNamespaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://www.w3.org/1999/xhtml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'content/{html}html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "ns = XMLNamespaces(html='http://www.w3.org/1999/xhtml')\n",
    "doc.find(ns('content/{html}html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.findtext(ns('content/{html}html/{html}head/{html}title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "解析含有命名空间的XML文档会比较繁琐。上面的 XMLNamespaces 仅仅是允许你使用缩略名代替完整的URI将其变得稍微简洁一点。\n",
    "\n",
    "在基本的 `ElementTree` 解析中没有任何途径获取命名空间的信息。\n",
    "\n",
    "但是，如果你使用 `iterparse()` 函数的话就可以获取更多关于命名空间处理范围的信息。例如：\n",
    "\n",
    "```python\n",
    ">>> from xml.etree.ElementTree import iterparse\n",
    ">>> for evt, elem in iterparse('ns2.xml', ('end', 'start-ns', 'end-ns')):\n",
    "... print(evt, elem)\n",
    "...\n",
    "end <Element 'author' at 0x10110de10>\n",
    "start-ns ('', 'http://www.w3.org/1999/xhtml')\n",
    "end <Element '{http://www.w3.org/1999/xhtml}title' at 0x1011131b0>\n",
    "end <Element '{http://www.w3.org/1999/xhtml}head' at 0x1011130a8>\n",
    "end <Element '{http://www.w3.org/1999/xhtml}h1' at 0x101113310>\n",
    "end <Element '{http://www.w3.org/1999/xhtml}body' at 0x101113260>\n",
    "end <Element '{http://www.w3.org/1999/xhtml}html' at 0x10110df70>\n",
    "end-ns None\n",
    "end <Element 'content' at 0x10110de68>\n",
    "end <Element 'top' at 0x10110dd60>\n",
    ">>> elem # This is the topmost element\n",
    "<Element 'top' at 0x10110dd60>\n",
    ">>>\n",
    "```\n",
    "\n",
    "最后一点，如果你要处理的XML文本除了要使用到其他高级XML特性外，还要使用到命名空间，建议你最好是使用 `lxml` 函数库来代替 `ElementTree`。\n",
    "\n",
    "例如，`lxml` 对利用DTD验证文档、更好的XPath支持和一些其他高级XML特性等都提供了更好的支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 与关系型数据库的交互\n",
    "\n",
    "* 问题\n",
    "\n",
    "在关系型数据库中查询、增加或删除记录。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "Python中表示多行数据的标准方式是一个由元组构成的序列。例如：\n",
    "```python\n",
    "stocks = [\n",
    "    ('GOOG', 100, 490.1),\n",
    "    ('AAPL', 50, 545.75),\n",
    "    ('FB', 150, 7.45),\n",
    "    ('HPQ', 75, 33.2),\n",
    "]\n",
    "```\n",
    "\n",
    "依据PEP249，通过这种形式提供数据，可以很容易的使用Python标准数据库API和关系型数据库进行交互。\n",
    "\n",
    "所有数据库上的操作都通过SQL查询语句来完成。每一行输入输出数据用一个元组来表示。\n",
    "\n",
    "为了演示说明，你可以使用Python标准库中的 `sqlite3` 模块。如果你使用的是一个不同的数据库(比如MySql、Postgresql或者ODBC)， 还得安装相应的第三方模块来提供支持。不过相应的编程接口几乎都是一样的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步是连接到数据库。通常你要执行 `connect()` 函数， 给它提供一些数据库名、主机、用户名、密码和其他必要的一些参数。\n",
    "```python\n",
    "import sqlite3\n",
    "db = sqlite3.connect('database.db')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了处理数据，下一步你需要创建一个游标。一旦你有了游标，那么你就可以执行SQL查询语句了。比如：\n",
    "```python\n",
    ">>> c = db.cursor()\n",
    ">>> c.execute('create table portfolio (symbol text, shares integer, price real)')\n",
    "<sqlite3.Cursor object at 0x10067a730>\n",
    ">>> db.commit()\n",
    "```\n",
    "\n",
    "为了向数据库表中插入多条记录，使用类似下面这样的语句：\n",
    "```python\n",
    ">>> c.executemany('insert into portfolio values (?,?,?)', stocks)\n",
    "<sqlite3.Cursor object at 0x10067a730>\n",
    ">>> db.commit()\n",
    "```\n",
    "\n",
    "为了执行某个查询，使用像下面这样的语句：\n",
    "```python\n",
    ">>> for row in db.execute('select * from portfolio'):\n",
    "        print(row)\n",
    "\n",
    "('GOOG', 100, 490.1)\n",
    "('AAPL', 50, 545.75)\n",
    "('FB', 150, 7.45)\n",
    "('HPQ', 75, 33.2)\n",
    "```\n",
    "\n",
    "如果你想接受用户输入作为参数来执行查询操作，必须确保你使用下面这样的占位符``?``来进行引用参数：\n",
    "```python\n",
    ">>> min_price = 100\n",
    ">>> for row in db.execute('select * from portfolio where price >= ?',\n",
    "                          (min_price,)):\n",
    "...     print(row)\n",
    "...\n",
    "('GOOG', 100, 490.1)\n",
    "('AAPL', 50, 545.75)\n",
    "```\n",
    "\n",
    "* 讨论\n",
    "\n",
    "在比较低的级别上和数据库交互是非常简单的。你只需提供SQL语句并调用相应的模块就可以更新或提取数据了。虽说如此，还是有一些比较棘手的细节问题需要你逐个列出去解决。\n",
    "\n",
    "一个难点是数据库中的数据和Python类型直接的映射。对于日期类型，通常可以使用 datetime 模块中的 datetime 实例， 或者可能是 time 模块中的系统时间戳。 对于数字类型，特别是使用到小数的金融数据，可以用 decimal 模块中的 Decimal 实例来表示。 不幸的是，对于不同的数据库而言具体映射规则是不一样的，你必须参考相应的文档。\n",
    "\n",
    "另外一个更加复杂的问题就是SQL语句字符串的构造。 你千万不要使用Python字符串格式化操作符(如%)或者 .format() 方法来创建这样的字符串。 如果传递给这些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受SQL注入攻击(参考 http://xkcd.com/327 )。 查询语句中的通配符 ? 指示后台数据库使用它自己的字符串替换机制，这样更加的安全。\n",
    "\n",
    "不幸的是，不同的数据库后台对于通配符的使用是不一样的。大部分模块使用 `?` 或 `%s` ， 还有其他一些使用了不同的符号，比如:0或:1来指示参数。同样的，你还是得去参考你使用的数据库模块相应的文档。 一个数据库模块的 paramstyle 属性包含了参数引用风格的信息。\n",
    "\n",
    "对于简单的数据库数据的读写问题，使用数据库API通常非常简单。 如果你要处理更加复杂的问题，建议你使用更加高级的接口，比如一个对象关系映射ORM所提供的接口。 类似 SQLAlchemy 这样的库允许你使用Python类来表示一个数据库表， 并且能在隐藏底层SQL的情况下实现各种数据库的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 编码和解码十六进制数\n",
    "\n",
    "* 问题\n",
    "\n",
    "将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成一个十六进制字符串。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "如果你只是简单的解码或编码一个十六进制的原始字符串，可以使用 `binascii` 模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656c6c6f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial byte string\n",
    "s = b'hello'\n",
    "# Encode as hex\n",
    "import binascii\n",
    "h = binascii.b2a_hex(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode back to bytes\n",
    "binascii.a2b_hex(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似的功能同样可以在 `base64` 模块中找到。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656C6C6F'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "h = base64.b16encode(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b16decode(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "大部分情况下，通过使用上述的函数来转换十六进制是很简单的。上面两种技术的主要不同在于大小写的处理。\n",
    "\n",
    "函数 `base64.b16decode()` 和 `base64.b16encode()` 只能操作大写形式的十六进制字母，而 `binascii` 模块中的函数大小写都能处理。\n",
    "\n",
    "还有一点需要注意的是编码函数所产生的输出总是一个字节字符串。\n",
    "\n",
    "如果想强制以Unicode形式输出，你需要增加一个额外的界面步骤。例如：\n",
    "\n",
    "```python\n",
    ">>> h = base64.b16encode(s)\n",
    ">>> print(h)\n",
    "b'68656C6C6F'\n",
    ">>> print(h.decode('ascii'))\n",
    "68656C6C6F\n",
    ">>>\n",
    "```\n",
    "\n",
    "在解码十六进制数时，函数 `b16decode()` 和 `a2b_hex()` 可以接受字节或unicode字符串。\n",
    "\n",
    "但是，unicode字符串必须仅仅只包含ASCII编码的十六进制数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 编码解码Base64数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "需要使用 `Base64` 格式解码或编码二进制数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "`base64` 模块中有两个函数 `b64encode()` and `b64decode()` 可以帮你解决这个问题。例如;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# Some byte data\n",
    "s = b'hello'\n",
    "\n",
    "# Encode as Base64\n",
    "a = base64.b64encode(s)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode from Base64\n",
    "base64.b64decode(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "`Base64` 编码仅仅用于面向字节的数据比如字节字符串和字节数组。\n",
    "\n",
    "此外，编码处理的输出结果总是一个字节字符串。\n",
    "\n",
    "如果你想混合使用 `Base64` 编码的数据和 `Unicode` 文本，你必须添加一个额外的解码步骤。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aGVsbG8='"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = base64.b64encode(s).decode('ascii')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当解码 `Base64` 的时候，`字节字符串` 和 `Unicode文本` 都可以作为参数。但是，`Unicode` 字符串只能包含 `ASCII字符`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.11 读写二进制数组数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "读写一个二进制数组的结构化数据到Python元组中。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "可以使用 `struct` 模块处理二进制数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一段示例代码将一个Python元组列表写入一个二进制文件，并使用 struct 将每个元组编码为一个结构体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    \"\"\"Write a sequence of tuples to a binary file of strucutres.\"\"\"\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))\n",
    "\n",
    "records = [(1, 2.3, 4.5),\n",
    "           (6, 7.8, 9.0),\n",
    "           (12, 13.4, 56.7)\n",
    "        ]\n",
    "\n",
    "with open('data.b', 'wb') as f:\n",
    "    write_records(records, '<idd', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有很多种方法来读取这个文件并返回一个元组列表。 首先，如果你打算以块的形式增量读取文件，你可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.3, 4.5)\n",
      "(6, 7.8, 9.0)\n",
      "(12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)\n",
    "\n",
    "with open('data.b', 'rb') as f:\n",
    "    for rec in read_records('<idd', f):\n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想将整个文件一次性读取到一个字节字符串中，然后在分片解析。那么你可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.3, 4.5)\n",
      "(6, 7.8, 9.0)\n",
      "(12, 13.4, 56.7)\n"
     ]
    }
   ],
   "source": [
    "def unpack_records(format, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack_from(data, offset)\n",
    "            for offset in range(0, len(data), record_struct.size))\n",
    "\n",
    "with open('data.b', 'rb') as f:\n",
    "    data = f.read()\n",
    "    for rec in unpack_records('<idd', data):\n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种情况下的结果都是一个可返回用来创建该文件的原始元组的可迭代对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "对于需要编码和解码二进制数据的程序而言，通常会使用 `struct` 模块。\n",
    "\n",
    "为了声明一个新的结构体，只需要像这样创建一个 `Struct` 实例即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little endian 32-bit integer, two double precision floats\n",
    "record_struct = Struct('<idd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结构体通常会使用一些结构码值i, d, f等。\n",
    "\n",
    "这些代码分别代表某个特定的二进制数据类型如32位整数，64位浮点数，32位浮点数等。\n",
    "\n",
    "第一个字符 `<` 指定了字节顺序，表示”低位在前”。更改这个字符为 `>` 表示高位在前，`!` 表示网络字节顺序。\n",
    "\n",
    "产生的 `Struct` 实例有很多属性和方法用来操作相应类型的结构。\n",
    "\n",
    "`size` 属性包含了结构的字节数，这在I/O操作时非常有用。\n",
    "\n",
    "`pack()` 和 `unpack()` 方法被用来打包和解包数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct = Struct('<idd')\n",
    "record_struct.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.pack(1, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 3.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.unpack(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候你还会看到 `pack()` 和 `unpack()` 操作以模块级别函数被调用，类似下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "struct.pack('<idd', 1, 2.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.0, 3.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.unpack('<idd', _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样可以工作，但是感觉没有实例方法那么优雅，特别是在你代码中同样的结构出现在多个地方的时候。通过创建一个 Struct 实例，格式代码只会指定一次并且所有的操作被集中处理。 这样一来代码维护就变得更加简单了(因为你只需要改变一处代码即可)。\n",
    "\n",
    "读取二进制结构的代码要用到一些非常有趣而优美的编程技巧。 在函数 `read_records` 中，`iter()` 被用来创建一个返回固定大小数据块的迭代器，参考5.8小节。 这个迭代器会不断的调用一个用户提供的可调用对象(比如 `lambda: f.read(record_struct.size)`)， 直到它返回一个特殊的值(如 `b''`)，这时候迭代停止。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x154832670b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('data.b', 'rb')\n",
    "chunks = iter(lambda: f.read(20), b'')\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x01\\x00\\x00\\x00ffffff\\x02@\\x00\\x00\\x00\\x00\\x00\\x00\\x12@'\n",
      "b'\\x06\\x00\\x00\\x00333333\\x1f@\\x00\\x00\\x00\\x00\\x00\\x00\"@'\n",
      "b'\\x0c\\x00\\x00\\x00\\xcd\\xcc\\xcc\\xcc\\xcc\\xcc*@\\x9a\\x99\\x99\\x99\\x99YL@'\n"
     ]
    }
   ],
   "source": [
    "for chk in chunks:\n",
    "    print(chk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个可迭代对象的一个原因是它能允许使用一个生成器推导来创建记录。如果你不使用这种技术，那么代码可能会像下面这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    while True:\n",
    "        chk = f.read(record_struct.size)\n",
    "        if chk == b'':\n",
    "            break\n",
    "        yield record_struct.unpack(chk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在函数 `unpack_records()` 中使用了另外一种方法 `unpack_from()`。\n",
    "\n",
    "`unpack_from()` 对于从一个大型二进制数组中提取二进制数据非常有用，因为它不会产生任何的临时对象或者进行内存复制操作。\n",
    "\n",
    "你只需要给它一个字节字符串(或数组)和一个字节偏移量，它会从那个位置开始直接解包数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你使用 `unpack()` 来代替 `unpack_from()`，你需要修改代码来构造大量的小的切片以及进行偏移量的计算。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_records(fromat, data):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack(data[offset: offset + record_struct.size])\n",
    "            for offset in range(0, len(data), record_struct.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方案除了代码看上去很复杂外，还得做很多额外的工作，因为它执行了大量的偏移量计算，复制数据以及构造小的切片对象。\n",
    "\n",
    "如果你准备从读取到的一个大型字节字符串中解包大量的结构体的话，`unpack_from()` 会表现的更出色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在解包的时候，`collections` 模块中的命名元组对象或许是你想要用到的。它可以让你给返回元组设置属性名称。例如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在解包的时候，collections 模块中的命名元组对象或许是你想要用到的。 它可以让你给返回元组设置属性名称。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "read of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-376cbf16c91f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<idd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-376cbf16c91f>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<idd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-7bad1ba7c1de>\u001b[0m in \u001b[0;36mread_records\u001b[1;34m(format, f)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrecord_struct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mchk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_struct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: read of closed file"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Record = namedtuple('Record', ['kind','x','y'])\n",
    "\n",
    "with open('data.b', 'rb') as f:\n",
    "    records = (Record(*r) for r in read_records('<idd', f))\n",
    "\n",
    "for r in records:\n",
    "    print(r.kind, r.x, r.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的程序需要处理大量的二进制数据，你最好使用 `numpy` 模块。\n",
    "\n",
    "例如，你可以将一个二进制数据读取到一个结构化数组中而不是一个元组列表中。就像下面这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 1,  2.3,  4.5), ( 6,  7.8,  9. ), (12, 13.4, 56.7)],\n",
       "      dtype=[('f0', '<i4'), ('f1', '<f8'), ('f2', '<f8')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = open('data.b', 'rb')\n",
    "records = np.fromfile(f, dtype='<i,<d,<d')\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2.3, 4.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7.8, 9.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你需要从已知的文件格式(如图片格式，图形文件，HDF5等)中读取二进制数据时，\n",
    "\n",
    "先检查看看Python是不是已经提供了现存的模块。因为不到万不得已没有必要去重复造轮子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.12 读取嵌套和可变长二进制数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "读取包含嵌套或者可变长记录集合的复杂二进制格式的数据。这些数据可能包含图片、视频、电子地图文件等。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "`struct` 模块可被用来编码/解码几乎所有类型的二进制的数据结构。\n",
    "\n",
    "为了解释清楚这种数据，假设你用下面的Python数据结构 来表示一个组成一系列多边形的点的集合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = [\n",
    "    [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],\n",
    "    [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],\n",
    "    [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "现在假设这个数据被编码到一个以下列头部开始的二进制文件中去：\n",
    "\n",
    "+------+--------+---------------------------------+\n",
    "|Byte  | Type   |  Description                    |\n",
    "+======+========+=================================+\n",
    "|0     | int    |  文件代码（0x1234, 小端）          |\n",
    "+------+--------+---------------------------------+\n",
    "|4     | double |  x 的最小值（小端）                |\n",
    "+------+--------+---------------------------------+\n",
    "|12    | double |  y 的最小值（小端）                |\n",
    "+------+--------+---------------------------------+\n",
    "|20    | double |  x 的最大值（小端）                |\n",
    "+------+--------+---------------------------------+\n",
    "|28    | double |  y 的最大值（小端）                |\n",
    "+------+--------+---------------------------------+\n",
    "|36    | int    |  三角形数量（小端）                |\n",
    "+------+--------+---------------------------------+\n",
    "\n",
    "\n",
    "紧跟着头部是一系列的多边形记录，编码格式如下：\n",
    "\n",
    "+------+--------+-------------------- ----------------------+\n",
    "|Byte  | Type   |  Description                              |\n",
    "+======+========+===========================================+\n",
    "|0     | int    |  记录长度（N字节）                           |\n",
    "+------+--------+-------------------------------------------+\n",
    "|4-N   | Points |  (X,Y) 坐标，以浮点数表示                    |\n",
    "+------+--------+-------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了写这样的文件，你可以使用如下的Python代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import itertools\n",
    "\n",
    "\n",
    "def write_polys(filename, polys):\n",
    "    # Determine bounding box\n",
    "    flattened = list(itertools.chain(*polys))\n",
    "    min_x = min(x for x, y in flattened)\n",
    "    max_x = max(x for x, y in flattened)\n",
    "    min_y = min(y for x, y in flattened)\n",
    "    max_y = max(y for x, y in flattened)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(struct.pack('<iddddi', 0x1234, min_x, min_y, max_x, max_y, len(polys)))\n",
    "\n",
    "        for poly in polys:\n",
    "            size = len(poly) * struct.calcsize('<dd')\n",
    "            f.write(struct.pack('<i', size + 4))\n",
    "            for pt in poly:\n",
    "                f.write(struct.pack('<dd', *pt))\n",
    "\n",
    "# Call it with our polygon data\n",
    "write_polys('polys.bin', polys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据读取回来的时候，可以利用函数 `struct.unpack()` ，代码很相似，基本就是上面写操作的逆序。如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_polys(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the header\n",
    "        header = f.read(40)\n",
    "        file_code, min_x, min_y, max_x, max_y, num_polys = struct.unpack('<iddddi', header)\n",
    "        polys = []\n",
    "        for n in range(num_polys):\n",
    "            pbytes, = struct.unpack('<i', f.read(4))\n",
    "            poly = []\n",
    "            for m in range(pbytes // 16):\n",
    "                pt = struct.unpack('<dd', f.read(16))\n",
    "                poly.append(pt)\n",
    "            polys.append(poly)\n",
    "    return polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管这个代码可以工作，但是里面混杂了很多读取、解包数据结构和其他细节的代码。如果用这样的代码来处理真实的数据文件，那未免也太繁杂了点。\n",
    "\n",
    "因此很显然应该有另一种解决方法可以简化这些步骤，让程序员只关注自最重要的事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来会逐步演示一个更加优秀的解析字节数据的方案。目标是可以给程序员提供一个高级的文件格式化方法，并简化读取和解包数据的细节。\n",
    "\n",
    "但是我要先提醒你，本小节接下来的部分代码应该是整本书中最复杂最高级的例子，使用了大量的面向对象编程和元编程技术。一定要仔细的阅读我们的讨论部分，另外也要参考下其他章节内容。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "首先，当读取字节数据的时候，通常在文件开始部分会包含文件头和其他的数据结构。\n",
    "\n",
    "尽管struct模块可以解包这些数据到一个元组中去，另外一种表示这种信息的方式就是使用一个类。 就像下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "\n",
    "class StructField:\n",
    "    # Descriptor representing a simple structure field\n",
    "    def __init__(self, format, offset):\n",
    "        self.format = format\n",
    "        self.offset = offset\n",
    "\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            r = struct.unpack_from(self.format, instance._buffer, self.offset)\n",
    "            return r[0] if len(r) == 1 else r\n",
    "\n",
    "\n",
    "class Structure:\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = memoryview(bytedata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用了一个描述器来表示每个结构字段，每个描述器包含一个结构兼容格式的代码以及一个字节偏移量，存储在内部的内存缓冲中。\n",
    "\n",
    "在 `__get__()` 方法中，`struct.unpack_from()` 函数被用来从缓冲中解包一个值，省去了额外的分片或复制操作步骤。\n",
    "\n",
    "`Structure` 类就是一个基础类，接受字节数据并存储在内部的内存缓冲中，并被 `StructField` 描述器使用。\n",
    "\n",
    "这里使用了 `memoryview()` ，我们会在后面详细讲解它是用来干嘛的。\n",
    "\n",
    "使用这个代码，你现在就能定义一个高层次的结构对象来表示上面表格信息所期望的文件格式。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyHeader(Structure):\n",
    "    file_code = StructField('<i', 0)\n",
    "    min_x = StructField('<d', 4)\n",
    "    min_y = StructField('<d', 12)\n",
    "    max_x = StructField('<d', 20)\n",
    "    max_y = StructField('<d', 28)\n",
    "    num_polys = StructField('<i', 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的例子利用这个类来读取之前我们写入的多边形数据的头部数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader(f.read(40))\n",
    "phead.file_code == 0x1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.num_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phead.min_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个很有趣，不过这种方式还是有一些烦人的地方。\n",
    "1. 首先，尽管你获得了一个类接口，但是这个代码还是有点臃肿，还需要使用者指定很多底层的细节(比如重复使用 StructField ，指定偏移量等)。\n",
    "2. 另外，返回的结果类同样确实一些便利的方法来计算结构的总数。\n",
    "\n",
    "任何时候只要你遇到了像这样冗余的类定义，你应该考虑下使用**类装饰器或元类**。\n",
    "\n",
    "元类有一个特性就是它能够被用来填充许多低层的实现细节，从而释放使用者的负担。\n",
    "\n",
    "下面我来举个例子，使用元类稍微改造下我们的 Structure 类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureMeta(type):\n",
    "    '''\n",
    "    Metaclass that automatically creates StructField descriptors\n",
    "    '''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fields:\n",
    "            if format.startswith(('<','>','!','@')):\n",
    "                byte_order = format[0]\n",
    "                format = format[1:]\n",
    "            format = byte_order + format\n",
    "            setattr(self, fieldname, StructField(format, offset))\n",
    "            offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)\n",
    "\n",
    "class Structure(metaclass=StructureMeta):\n",
    "    def __init__(self, bytedata):\n",
    "        self._buffer = bytedata\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, f):\n",
    "        return cls(f.read(cls.struct_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用新的 Structure 类，你可以像下面这样定义一个结构：\n",
    "\n",
    "\n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        ('d', 'min_x'),\n",
    "        ('d', 'min_y'),\n",
    "        ('d', 'max_x'),\n",
    "        ('d', 'max_y'),\n",
    "        ('i', 'num_polys')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们添加的类方法 `from_file()` 让我们在不需要知道任何数据的大小和结构的情况下就能轻松的从文件中读取数据。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('polys.bin', 'rb')\n",
    "phead = PolyHeader.from_file(f)\n",
    "phead.file_code == 0x1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦你开始使用了元类，你就可以让它变得更加智能。例如，假设你还想支持嵌套的字节结构， 下面是对前面元类的一个小的改进，提供了一个新的辅助描述器来达到想要的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedStruct:\n",
    "    '''\n",
    "    Descriptor representing a nested structure\n",
    "    '''\n",
    "    def __init__(self, name, struct_type, offset):\n",
    "        self.name = name\n",
    "        self.struct_type = struct_type\n",
    "        self.offset = offset\n",
    "\n",
    "    def __get__(self, instance, cls):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        else:\n",
    "            data = instance._buffer[self.offset:\n",
    "                            self.offset+self.struct_type.struct_size]\n",
    "            result = self.struct_type(data)\n",
    "            # Save resulting structure back on instance to avoid\n",
    "            # further recomputation of this step\n",
    "            setattr(instance, self.name, result)\n",
    "            return result\n",
    "\n",
    "class StructureMeta(type):\n",
    "    '''\n",
    "    Metaclass that automatically creates StructField descriptors\n",
    "    '''\n",
    "    def __init__(self, clsname, bases, clsdict):\n",
    "        fields = getattr(self, '_fields_', [])\n",
    "        byte_order = ''\n",
    "        offset = 0\n",
    "        for format, fieldname in fields:\n",
    "            if isinstance(format, StructureMeta):\n",
    "                setattr(self, fieldname,\n",
    "                        NestedStruct(fieldname, format, offset))\n",
    "                offset += format.struct_size\n",
    "            else:\n",
    "                if format.startswith(('<','>','!','@')):\n",
    "                    byte_order = format[0]\n",
    "                    format = format[1:]\n",
    "                format = byte_order + format\n",
    "                setattr(self, fieldname, StructField(format, offset))\n",
    "                offset += struct.calcsize(format)\n",
    "        setattr(self, 'struct_size', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这段代码中，NestedStruct 描述器被用来叠加另外一个定义在某个内存区域上的结构。 它通过将原始内存缓冲进行切片操作后实例化给定的结构类型。由于底层的内存缓冲区是通过一个内存视图初始化的， 所以这种切片操作不会引发任何的额外的内存复制。相反，它仅仅就是之前的内存的一个叠加而已。 另外，为了防止重复实例化，通过使用和8.10小节同样的技术，描述器保存了该实例中的内部结构对象。\n",
    "\n",
    "使用这个新的修正版，你就可以像下面这样编写："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Point' has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-56b3291d88be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     ]\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPolyHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStructure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     _fields_ = [\n\u001b[0;32m      9\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'<i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'file_code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-1cc106727922>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, clsname, bases, clsdict)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'!'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'@'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mbyte_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Point' has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "class Point(Structure):\n",
    "    _fields_ = [\n",
    "        ('<d', 'x'),\n",
    "        ('d', 'y')\n",
    "    ]\n",
    "\n",
    "class PolyHeader(Structure):\n",
    "    _fields_ = [\n",
    "        ('<i', 'file_code'),\n",
    "        (Point, 'min'), # nested struct\n",
    "        (Point, 'max'), # nested struct\n",
    "        ('i', 'num_polys')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: 0612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.13 数据的累加与统计操作\n",
    "\n",
    "* 问题\n",
    "\n",
    "你需要处理一个很大的数据集并需要计算数据总和或其他统计量。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "对于任何涉及到统计、时间序列以及其他相关技术的数据分析问题，都可以考虑使用 `Pandas库` 。\n",
    "\n",
    "为了让你先体验下，下面是一个使用Pandas来分析芝加哥城市的 老鼠和啮齿类动物数据库 的例子。 在我写这篇文章的时候，这个数据库是一个拥有大概74,000行数据的CSV文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> import pandas\n",
    "\n",
    ">>> # Read a CSV file, skipping last line\n",
    ">>> rats = pandas.read_csv('rats.csv', skip_footer=1)\n",
    ">>> rats\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 74055 entries, 0 to 74054\n",
    "Data columns:\n",
    "Creation Date 74055 non-null values\n",
    "Status 74055 non-null values\n",
    "Completion Date 72154 non-null values\n",
    "Service Request Number 74055 non-null values\n",
    "Type of Service Request 74055 non-null values\n",
    "Number of Premises Baited 65804 non-null values\n",
    "Number of Premises with Garbage 65600 non-null values\n",
    "Number of Premises with Rats 65752 non-null values\n",
    "Current Activity 66041 non-null values\n",
    "Most Recent Action 66023 non-null values\n",
    "Street Address 74055 non-null values\n",
    "ZIP Code 73584 non-null values\n",
    "X Coordinate 74043 non-null values\n",
    "Y Coordinate 74043 non-null values\n",
    "Ward 74044 non-null values\n",
    "Police District 74044 non-null values\n",
    "Community Area 74044 non-null values\n",
    "Latitude 74043 non-null values\n",
    "Longitude 74043 non-null values\n",
    "Location 74043 non-null values\n",
    "dtypes: float64(11), object(9)\n",
    "\n",
    ">>> # Investigate range of values for a certain field\n",
    ">>> rats['Current Activity'].unique()\n",
    "array([nan, Dispatch Crew, Request Sanitation Inspector], dtype=object)\n",
    ">>> # Filter the data\n",
    ">>> crew_dispatched = rats[rats['Current Activity'] == 'Dispatch Crew']\n",
    ">>> len(crew_dispatched)\n",
    "65676\n",
    ">>>\n",
    "\n",
    ">>> # Find 10 most rat-infested ZIP codes in Chicago\n",
    ">>> crew_dispatched['ZIP Code'].value_counts()[:10]\n",
    "60647 3837\n",
    "60618 3530\n",
    "60614 3284\n",
    "60629 3251\n",
    "60636 2801\n",
    "60657 2465\n",
    "60641 2238\n",
    "60609 2206\n",
    "60651 2152\n",
    "60632 2071\n",
    ">>>\n",
    "\n",
    ">>> # Group by completion date\n",
    ">>> dates = crew_dispatched.groupby('Completion Date')\n",
    "<pandas.core.groupby.DataFrameGroupBy object at 0x10d0a2a10>\n",
    ">>> len(dates)\n",
    "472\n",
    ">>>\n",
    "\n",
    ">>> # Determine counts on each day\n",
    ">>> date_counts = dates.size()\n",
    ">>> date_counts[0:10]\n",
    "Completion Date\n",
    "01/03/2011 4\n",
    "01/03/2012 125\n",
    "01/04/2011 54\n",
    "01/04/2012 38\n",
    "01/05/2011 78\n",
    "01/05/2012 100\n",
    "01/06/2011 100\n",
    "01/06/2012 58\n",
    "01/07/2011 1\n",
    "01/09/2012 12\n",
    ">>>\n",
    "\n",
    ">>> # Sort the counts\n",
    ">>> date_counts.sort()\n",
    ">>> date_counts[-10:]\n",
    "Completion Date\n",
    "10/12/2012 313\n",
    "10/21/2011 314\n",
    "09/20/2011 316\n",
    "10/26/2011 319\n",
    "02/22/2011 325\n",
    "10/26/2012 333\n",
    "03/17/2011 336\n",
    "10/13/2011 378\n",
    "10/14/2011 391\n",
    "10/07/2011 457\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嗯，看样子2011年10月7日对老鼠们来说是个很忙碌的日子啊！^_^\n",
    "\n",
    "* 讨论\n",
    "\n",
    "Pandas是一个拥有很多特性的大型函数库，我在这里不可能介绍完。 但是只要你需要去分析大型数据集合、对数据分组、计算各种统计量或其他类似任务的话，这个函数库真的值得你去看一看。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "145699e85a40168331a7cb4ae89765d59b9032ff9abe784a3aea13b1452c5e16"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('pytorch1.8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
