{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章：数据编码和处理\n",
    "这一章主要讨论使用Python处理各种不同方式编码的数据，比如CSV文件，JSON，XML和二进制包装记录。\n",
    "\n",
    "和数据结构那一章不同的是，这章不会讨论特殊的算法问题，而是关注于怎样获取和存储这些格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读写CSV数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想读写一个CSV格式的文件。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "对于大多数的CSV格式的数据读写问题，都可以使用 csv 库。 例如：假设你在一个名叫 `stocks.csv` 文件中有一些股票市场数据，就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "True\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "True\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "True\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "True\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "True\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 读取csv数据，转为元组序列\n",
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(isinstance(row, list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[0], row[1], row[2], row[3], row[4], row[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中，`row` 会是一个列表。\n",
    "\n",
    "因此，为了访问某个字段，你需要使用下标。\n",
    "\n",
    "如 `row[0]` 访问 `Symbol`的值，`row[4]` 访问 `Change` 的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "AA\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "AIG\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "AXP\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "BA\n",
      "Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "C\n",
      "Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n",
      "CAT\n"
     ]
    }
   ],
   "source": [
    "# 使用下标访问通常会引起混淆，使用 命名元组来索引数据。\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)  # 列名\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        # r is list\n",
    "        row = Row(*r)\n",
    "        print(row)\n",
    "        print(row.Symbol)  # 使用列名索引数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码允许使用列名如 `row.Symbol` 和 `row.Change` 代替下标访问数据。\n",
    "\n",
    "需要注意的是：这个只有在 **列名是合法的Python标识符** 的时候才生效。\n",
    "\n",
    "如果不是的话，你可能需要修改下原始的列名(如将非标识符字符替换成下划线之类的)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个选择就是**将数据读取到一个字典序列**中去。可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "AA\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "AIG\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "AXP\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        print(row['Symbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个版本中，你可以使用列名去访问每一行的数据了。比如，`row['Symbol']` 或者 `row['Change']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了写入CSV数据，你仍然可以使用csv模块，不过这时候先创建一个 `writer` 对象。例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你有一个字典序列的数据\n",
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "        {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "        {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n",
    "        'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "        ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "你应该优先选择 `csv` 模块分割或解析CSV数据。例如，你可能会像编写类似下面这样的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']\n",
      "['\"AA\"', '39.48', '\"6/11/2007\"', '\"9:36am\"', '-0.18', '181800\\n']\n",
      "['\"AIG\"', '71.38', '\"6/11/2007\"', '\"9:36am\"', '-0.15', '195500\\n']\n",
      "['\"AXP\"', '62.58', '\"6/11/2007\"', '\"9:36am\"', '-0.46', '935000\\n']\n",
      "['\"B', 'A\"', '98.31', '\"6/11/2007\"', '\"9:36am\"', '+0.12', '104800\\n']\n",
      "['\"C\"', '53.08', '\"6/11/2007\"', '\"9:36am\"', '-0.25', '360900\\n']\n",
      "['\"CAT\"', '78.29', '\"6/11/2007\"', '\"9:36am\"', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。\n",
    "* 如果某些字段值被引号包围，你不得不去除这些引号。\n",
    "* 如果一个被引号包围的字段碰巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。\n",
    "\n",
    "默认情况下，csv 库可识别Microsoft Excel所使用的CSV编码规则。这也是最常见的形式，并且也会给你带来最好的兼容性。\n",
    "\n",
    "然而，如果你查看csv的文档，就会发现有很多种方法将它应用到其他编码格式上(如修改分割字符等)。 例如，如果你想读取以tab分割的数据，可以这样做：\n",
    "\n",
    "```python\n",
    "# Example of reading tab-separated values\n",
    "with open('stock.tsv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        # Process row\n",
    "        print(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你正在读取CSV数据并将它们转换为 命名元组，需要注意对列名进行合法性认证。\n",
    "\n",
    "例如，一个CSV格式文件有一个包含非法标识符的列头行，类似下面这样：\n",
    "```\n",
    "Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452\n",
    "```\n",
    "\n",
    "这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。\n",
    "\n",
    "为了解决这问题，你可能不得不先去修正列标题。例如，可以像下面这样在非法标识符上使用一个正则表达式替换：\n",
    "\n",
    "```python\n",
    "import re\n",
    "with open('stock.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有重要的一点需要强调的是，csv产生的数据都是**字符串类型**的，它不会做任何其他类型的转换。\n",
    "\n",
    "如果你需要做这样的类型转换，你必须自己手动去实现。下面是一个在CSV数据上执行其他类型转换的例子：\n",
    "```python\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，下面是一个转换字典中特定字段的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n",
      "OrderedDict([('Symbol', 'AA'), ('Price', 39.48), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.18), ('Volume', 181800)])\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', 71.38), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.15), ('Volume', 195500)])\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', 62.58), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.46), ('Volume', 935000)])\n"
     ]
    }
   ],
   "source": [
    "print('Reading as dicts with type conversion')\n",
    "\n",
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常来讲，你可能并不想过多去考虑这些转换问题。在实际情况中，CSV文件都或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。\n",
    "\n",
    "因此，除非你的数据确实有保障是准确无误的，否则你必须考虑这些问题(你可能需要增加合适的错误处理机制)。\n",
    "\n",
    "最后，如果你读取CSV数据的目的是做数据分析和统计的话，你可能需要看一看 `Pandas` 包。\n",
    "\n",
    "Pandas 包含了一个非常方便的函数叫 `pandas.read_csv()`，它可以加载CSV数据到一个 `DataFrame` 对象中去。 然后利用这个对象你就可以生成各种形式的统计、过滤数据以及执行其他高级操作了。在6.13小节中会有这样一个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 读写JSON数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "读写JSON(JavaScript Object Notation)编码格式的数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "`json` 模块提供了一种很简单的方式来编码和解码JSON数据。其中两个主要的函数是 `json.dumps()` 和 `json.loads()`，\n",
    "\n",
    "要比其他序列化函数库如pickle的接口少得多。 下面演示如何将一个Python数据结构转换为JSON："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name': 'ACME',\n",
    "    'shares': 100,\n",
    "    'price': 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面演示如何将一个JSON编码的字符串转换回一个Python数据结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ACME', 'shares': 100, 'price': 542.23}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(json_str)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你要处理的是文件而不是字符串，你可以使用 `json.dump()` 和 `json.load()` 来编码和解码JSON数据。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "JSON编码支持的基本数据类型为 `None`，`bool`，`int`，`float` 和 `str`，以及包含这些类型数据的 `lists`，`tuples` 和 `dictionaries`。\n",
    "\n",
    "对于`dictionaries`，`keys` 需要是字符串类型（字典中任何非字符串类型的key在编码时会先转换为字符串）。\n",
    "\n",
    "为了遵循JSON规范，你应该只编码Python的 `lists` 和 `dictionaries`。 而且，在web应用程序中，顶层对象被编码为一个字典是一个标准做法。\n",
    "\n",
    "JSON编码的格式对于Python语法而已几乎是完全一样的，除了一些小的差异之外。比如，True会被映射为true，False被映射为false，而None会被映射为null。\n",
    "\n",
    "下面是一个例子，演示了编码后的字符串效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(False)\n",
    "\n",
    "d = {\n",
    "    'a': True,\n",
    "    'b': 'Hello',\n",
    "    'c': None\n",
    "    }\n",
    "\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你试着去检查JSON解码后的数据，你通常很难通过简单的打印来确定它的结构，特别是当数据的嵌套结构层次很深或者包含大量的字段时。\n",
    "\n",
    "为了解决这个问题，可以考虑使用 `pprint` 模块的 `pprint()` 函数来代替普通的 `print()` 函数。\n",
    "\n",
    "它会按照key的字母顺序并以一种更加美观的方式输出。 下面是一个演示如何漂亮的打印输出Twitter上搜索结果的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c709c61d976b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "\n",
    "u = urlopen('https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9398506483755601800%22%7D&n_type=-1&p_from=-1')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来讲，JSON解码会根据提供的数据创建 `dicts` 或`lists`。\n",
    "\n",
    "如果你想要创建其他类型的对象，可以给 `json.loads()` 传递 `object_pairs_hook` 或 `object_hook` 参数。\n",
    "\n",
    "例如，下面是演示如何解码JSON数据并在一个 `OrderedDict` 中保留其顺序的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是如何将一个JSON字典转换为一个Python对象例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(s, object_hook=JSONObject)\n",
    "data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON解码后的字典作为一个单个参数传递给 `__init__()`。然后，你就可以随意使用它了，比如作为一个实例字典来直接使用它。\n",
    "\n",
    "在编码JSON的时候，还有一些选项很有用。 如果你想获得漂亮的格式化字符串后输出，可以使用 `json.dumps()` 的 `indent` 参数。 它会使得输出和pprint()函数效果类似。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}\n"
     ]
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 50,\n",
      "    \"price\": 490.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对象实例通常并不是JSON可序列化的。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'Point' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-54699a8f2307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\pytorch1.8\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'Point' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "p = Point(2, 3)\n",
    "json.dumps(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个可序列化的字典。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你想反过来获取这个实例，可以这样做：\n",
    "# Dictionary mapping names to known classes\n",
    "classes = {\n",
    "    'Point' : Point\n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "        return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面是如何使用这些函数的例子：\n",
    "p = Point(2, 3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x28df66410b8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json 模块还有很多其他选项来控制更低级别的数字、特殊值如NaN等的解析。 可以参考官方文档获取更多细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 解析简单的XML数据\n",
    "\n",
    "* 问题\n",
    "\n",
    "你想从一个简单的XML文档中提取数据。\n",
    "\n",
    "* 解决方案\n",
    "\n",
    "可以使用 `xml.etree.ElementTree` 模块从简单的XML文档中提取数据。为了演示，假设你想解析 Planet Python上的RSS源。下面是相应的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed an dparse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Python: Build and Submit HTML Forms With Django – Part 4\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-forms-4/\n",
      "Python for Beginners: Create Decorators Using Classes in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/create-decorators-using-classes-in-python\n",
      "Quansight Labs Blog: IPython 8.0, Lessons learned maintaining software\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://labs.quansight.org/blog/2022/01/ipython-8.0-lessons-learned-maintaining-software/\n",
      "Python Circle: Django vs Node.js: Which One Is Better for Web Development?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pythoncircle.com/post/757/django-vs-nodejs-which-one-is-better-for-web-development/\n",
      "Kay Hayen: Nuitka Release 0.6.19\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://nuitka.net/posts/nuitka-release-0619.html\n",
      "Test and Code: 175: Who Should Do QA?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testandcode.com/175\n",
      "Read the Docs: Read the Docs newsletter - January 2022\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://blog.readthedocs.com/newsletter-january-2022/\n",
      "TestDriven.io: Introduction to Django Channels\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://testdriven.io/blog/django-channels/\n",
      "PyCoder’s Weekly: Issue #507 (Jan. 11, 2022)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://pycoders.com/issues/507\n",
      "Python for Beginners: Check For Prime Number in Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonforbeginners.com/basics/check-for-prime-number-in-python\n",
      "Real Python: Working With Pipenv\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/courses/working-with-pipenv/\n",
      "Sumana Harihareswara - Cogito, Ergo Sumana: Some Novel Python Packaging/Distribution/Inspection/Installation Projects\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://harihareswara.net/posts/2021/some-novel-python-packagingdistributioninspectioninstallation-projects/\n",
      "Python GUIs: Using Layouts to Position Widgets in PySide6 — Use layouts to effortlessly position widgets within the window (updated for PySide6)\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.pythonguis.com/tutorials/pyside6-layouts/\n",
      "Codementor: One-Hot Encoding in Data Science\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.codementor.io/abdelfettahbesbes/one-hot-encoding-in-data-science-1pe0lftu21\n",
      "Inspired Python: Solving Wordle Puzzles with Basic Python\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.inspiredpython.com/article/solving-wordle-puzzles-with-basic-python\n",
      "Real Python: Build and Handle POST Requests in Django – Part 3\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://realpython.com/django-social-post-3/\n",
      "ItsMyCode: How to Fix: KeyError in Pandas?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-keyerror-in-pandas/\n",
      "David Amos: 5 Ways To Use Python On An iPad\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://davidamos.dev/5-ways-to-use-python-on-an-ipad/\n",
      "ItsMyCode: How to Fix in Python ValueError: Trailing data?\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/how-to-fix-in-python-valueerror-trailing-data/\n",
      "Mike Driscoll: PyDev of the Week:  Lais Carvalho\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.blog.pythonlibrary.org/2022/01/10/pydev-of-the-week-lais-carvalho/\n",
      "Zato Blog: API development workflow with Zato\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://zato.io/blog/posts/zato-dev-workflow.html\n",
      "Matt Layman: Most Abstract Function First Is Better\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://www.mattlayman.com/blog/2022/most-abstract-function-first-better/\n",
      "Armin Ronacher: Dependency Risk and Funding\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "http://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding\n",
      "ItsMyCode: [Solved] NameError: name &#8216;pd&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-pd-is-not-defined/\n",
      "ItsMyCode: [Solved] NameError: name &#8216;np&#8217; is not defined\n",
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n",
      "https://itsmycode.com/solved-nameerror-name-np-is-not-defined/\n"
     ]
    }
   ],
   "source": [
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(data)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 讨论\n",
    "\n",
    "在很多应用程序中处理XML编码格式的数据是很常见的。不仅因为XML在Internet上面已经被广泛应用于数据交换，同时它也是一种存储应用程序数据的常用格式(比如字处理，音乐库等)。\n",
    "\n",
    "在很多情况下，当使用XML来仅仅存储数据的时候，对应的文档结构非常紧凑并且直观。 例如，上面例子中的RSS订阅源类似于下面的格式：\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "    <channel>\n",
    "        <title>Planet Python</title>\n",
    "        <link>http://planet.python.org/</link>\n",
    "        <language>en</language>\n",
    "        <description>Planet Python - http://planet.python.org/</description>\n",
    "        <item>\n",
    "            <title>Steve Holden: Python for Data Analysis</title>\n",
    "            <guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n",
    "            <link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n",
    "            <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "            <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "        </item>\n",
    "        <item>\n",
    "            <title>Python Diary: Been playing around with Object Databases</title>\n",
    "            <guid>http://www.pythondiary.com/...-object-databases.html</guid>\n",
    "            <link>http://www.pythondiary.com/...-object-databases.html</link>\n",
    "            <description>...</description>\n",
    "            <pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "        </item>\n",
    "        ...\n",
    "    </channel>\n",
    "</rss>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xml.etree.ElementTree.parse()` 函数解析整个XML文档并将其转换成一个文档对象。\n",
    "\n",
    "然后，你就能使用 `find()`、`iterfind()` 和 `findtext()` 等方法来搜索特定的XML元素了。\n",
    "\n",
    "这些函数的参数就是某个指定的标签名，例如 `channel/item` 或 `title`。\n",
    "\n",
    "每次指定某个标签时，你需要遍历整个文档结构。每次搜索操作会从一个起始元素开始进行。同样，每次操作所指定的标签名也是起始元素的相对路径。\n",
    "\n",
    "例如，执行 `doc.iterfind('channel/item')` 来搜索所有在 `channel` 元素下面的 `item` 元素。\n",
    "\n",
    "`doc` 代表文档的最顶层(也就是第一级的 rss 元素)。 然后接下来的调用 `item.findtext()` 会从已找到的 `item` 元素位置开始搜索。\n",
    "\n",
    "`ElementTree` 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有用。\n",
    "\n",
    "`tag` 属性包含了标签的名字，`text` 属性包含了内部的文本，而 `get()` 方法能获取属性值。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x28df65c19e8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x0000028DF66490E8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一点要强调的是 `xml.etree.ElementTree` 并不是XML解析的唯一方法。\n",
    "\n",
    "对于更高级的应用程序，你需要考虑使用 `lxml`。 它使用了和ElementTree同样的编程接口，因此上面的例子同样也适用于lxml。\n",
    "\n",
    "你只需要将刚开始的import语句换成 `from lxml.etree import parse` 就行了。\n",
    "\n",
    "`lxml` 完全遵循XML标准，并且速度也非常快，同时还支持验证，XSLT，和XPath等特性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "145699e85a40168331a7cb4ae89765d59b9032ff9abe784a3aea13b1452c5e16"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('pytorch1.8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
